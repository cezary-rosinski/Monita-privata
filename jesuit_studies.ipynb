{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c315a6-26a0-47aa-a8cc-eab289e4d41e",
   "metadata": {},
   "source": [
    "# Topic modeling for *Journal of Jesuit Studies*\n",
    "This Jupyter Notebook contains Python code for topic modeling of 322 articles from *Journal of Jesuit Studies* using [BERTopic](https://maartengr.github.io/BERTopic/index.html) technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc4fdc4-6b38-4320-b849-88b172a7760a",
   "metadata": {},
   "source": [
    "## Instalation of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f685257a-0e5c-40d6-a184-6a1bea3ac84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.backend import BaseEmbedder\n",
    "from umap import UMAP\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c63a2-c0d3-44b3-8b6b-e2a9445f68ce",
   "metadata": {},
   "source": [
    "## Creation of predefined functions for the pre-processing of article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e88b76c-bb6b-43e9-8762-bc685217b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def split_text(text, max_length=100):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i + max_length]) for i in range(0, len(words), max_length)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e1713-4b16-4357-813e-209193222407",
   "metadata": {},
   "source": [
    "## Upload of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8ec8d1-6b2b-4257-ad98-609207269211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 322/322 [00:01<00:00, 268.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 322/322 [03:16<00:00,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 322/322 [00:00<00:00, 11232.44it/s]\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Cezary\\Documents\\Monita-privata\\data\\konferencja-poznan\\txt/\"\n",
    "txt_files = [f for f in glob(f\"{path}*\", recursive=True)]\n",
    "\n",
    "txt_dict = {}\n",
    "for txt_file in tqdm(txt_files):\n",
    "    text_key = txt_file.split('\\\\')[-1].split('.')[0]\n",
    "    with open(txt_file, 'rt', encoding='utf-8') as f:\n",
    "        text_value = f.read()\n",
    "    txt_dict.update({text_key: text_value})\n",
    "\n",
    "texts = list(txt_dict.values())\n",
    "\n",
    "processed_texts = [preprocess_text(text) for text in tqdm(texts)]\n",
    "split_texts = []\n",
    "for text in tqdm(processed_texts):\n",
    "    split_texts.extend(split_text(text))\n",
    "split_texts = [text for text in split_texts if text.strip() != '']\n",
    "\n",
    "if len(split_texts) < 2:\n",
    "    raise ValueError(\"Niewystarczająca liczba tekstów po przetwarzaniu wstępnym. Dodaj więcej danych wejściowych.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575feef-45ef-4130-a818-d7f9ec18331f",
   "metadata": {},
   "source": [
    "## Model training for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b269ae-f0af-46b4-b323-baf6b9ecf2e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\bertopic\\_bertopic.py:3507\u001b[0m, in \u001b[0;36mBERTopic._cluster_embeddings\u001b[1;34m(self, umap_embeddings, documents, partial_fit, y)\u001b[0m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3507\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhdbscan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mumap_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3508\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:1205\u001b[0m, in \u001b[0;36mHDBSCAN.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric_kwargs)\n\u001b[0;32m   1198\u001b[0m (\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_,\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobabilities_,\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_persistence_,\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condensed_tree,\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_linkage_tree,\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_spanning_tree,\n\u001b[1;32m-> 1205\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mhdbscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_finite:\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;66;03m# remap indices to align with original data in the case of non-finite entries.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:884\u001b[0m, in \u001b[0;36mhdbscan\u001b[1;34m(X, min_cluster_size, min_samples, alpha, cluster_selection_epsilon, max_cluster_size, metric, p, leaf_size, algorithm, memory, approx_min_span_tree, gen_min_span_tree, core_dist_n_jobs, cluster_selection_method, allow_single_cluster, match_reference_implementation, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m             (single_linkage_tree, result_min_span_tree) \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39mcache(\n\u001b[0;32m    869\u001b[0m                 _hdbscan_boruvka_balltree\n\u001b[0;32m    870\u001b[0m             )(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    880\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    881\u001b[0m             )\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 884\u001b[0m     \u001b[43m_tree_to_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_linkage_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_single_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatch_reference_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;241m+\u001b[39m (result_min_span_tree,)\n\u001b[0;32m    895\u001b[0m )\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:80\u001b[0m, in \u001b[0;36m_tree_to_labels\u001b[1;34m(X, single_linkage_tree, min_cluster_size, cluster_selection_method, allow_single_cluster, match_reference_implementation, cluster_selection_epsilon, max_cluster_size)\u001b[0m\n\u001b[0;32m     79\u001b[0m stability_dict \u001b[38;5;241m=\u001b[39m compute_stability(condensed_tree)\n\u001b[1;32m---> 80\u001b[0m labels, probabilities, stabilities \u001b[38;5;241m=\u001b[39m \u001b[43mget_clusters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondensed_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstability_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_single_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch_reference_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (labels, probabilities, stabilities, condensed_tree, single_linkage_tree)\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:659\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.get_clusters\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:733\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.get_clusters\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m\n\u001b[0;32m     17\u001b[0m topic_model \u001b[38;5;241m=\u001b[39m BERTopic(\n\u001b[0;32m     18\u001b[0m     embedding_model\u001b[38;5;241m=\u001b[39menglish_embedder,\n\u001b[0;32m     19\u001b[0m     vectorizer_model\u001b[38;5;241m=\u001b[39mvectorizer_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     calculate_probabilities\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     topics, probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during model fitting: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\bertopic\\_bertopic.py:411\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[1;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[0;32m    408\u001b[0m umap_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_dimensionality(embeddings, y)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Cluster reduced embeddings\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m documents, probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cluster_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mumap_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;66;03m# Sort and Map Topic IDs by their frequency\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_topics:\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\bertopic\\_bertopic.py:3509\u001b[0m, in \u001b[0;36mBERTopic._cluster_embeddings\u001b[1;34m(self, umap_embeddings, documents, partial_fit, y)\u001b[0m\n\u001b[0;32m   3507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhdbscan_model\u001b[38;5;241m.\u001b[39mfit(umap_embeddings, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m   3508\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m-> 3509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhdbscan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mumap_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3511\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3512\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhdbscan_model\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:1205\u001b[0m, in \u001b[0;36mHDBSCAN.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1195\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1196\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric_kwargs)\n\u001b[0;32m   1198\u001b[0m (\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_,\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobabilities_,\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_persistence_,\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condensed_tree,\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_linkage_tree,\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_spanning_tree,\n\u001b[1;32m-> 1205\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mhdbscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_finite:\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;66;03m# remap indices to align with original data in the case of non-finite entries.\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condensed_tree \u001b[38;5;241m=\u001b[39m remap_condensed_tree(\n\u001b[0;32m   1210\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condensed_tree, internal_to_raw, outliers\n\u001b[0;32m   1211\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:884\u001b[0m, in \u001b[0;36mhdbscan\u001b[1;34m(X, min_cluster_size, min_samples, alpha, cluster_selection_epsilon, max_cluster_size, metric, p, leaf_size, algorithm, memory, approx_min_span_tree, gen_min_span_tree, core_dist_n_jobs, cluster_selection_method, allow_single_cluster, match_reference_implementation, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    868\u001b[0m             (single_linkage_tree, result_min_span_tree) \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39mcache(\n\u001b[0;32m    869\u001b[0m                 _hdbscan_boruvka_balltree\n\u001b[0;32m    870\u001b[0m             )(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    880\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    881\u001b[0m             )\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 884\u001b[0m     \u001b[43m_tree_to_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_linkage_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_single_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatch_reference_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;241m+\u001b[39m (result_min_span_tree,)\n\u001b[0;32m    895\u001b[0m )\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:80\u001b[0m, in \u001b[0;36m_tree_to_labels\u001b[1;34m(X, single_linkage_tree, min_cluster_size, cluster_selection_method, allow_single_cluster, match_reference_implementation, cluster_selection_epsilon, max_cluster_size)\u001b[0m\n\u001b[0;32m     78\u001b[0m condensed_tree \u001b[38;5;241m=\u001b[39m condense_tree(single_linkage_tree, min_cluster_size)\n\u001b[0;32m     79\u001b[0m stability_dict \u001b[38;5;241m=\u001b[39m compute_stability(condensed_tree)\n\u001b[1;32m---> 80\u001b[0m labels, probabilities, stabilities \u001b[38;5;241m=\u001b[39m \u001b[43mget_clusters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondensed_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstability_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_single_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch_reference_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (labels, probabilities, stabilities, condensed_tree, single_linkage_tree)\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:659\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.get_clusters\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:733\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.get_clusters\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "# sentence_model = SentenceTransformer(\"allegro/herbert-base-cased\")\n",
    "sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "class EnglishEmbedder(BaseEmbedder):\n",
    "    def __init__(self, embedding_model):\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "    def embed(self, documents, verbose=False):\n",
    "        return self.embedding_model.encode(documents, show_progress_bar=verbose)\n",
    "\n",
    "english_embedder = EnglishEmbedder(sentence_model)\n",
    "vectorizer_model = CountVectorizer(stop_words=stop_words, ngram_range=(1, 2))\n",
    "umap_model = UMAP(n_neighbors=10, n_components=5, min_dist=0.1, metric='cosine')\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=english_embedder,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    umap_model=umap_model,\n",
    "    top_n_words=10,\n",
    "    n_gram_range=(1, 2),\n",
    "    min_topic_size=10,\n",
    "    calculate_probabilities=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    topics, probabilities = topic_model.fit_transform(split_texts)\n",
    "except ValueError as e:\n",
    "    print(f\"Error during model fitting: {e}\")\n",
    "    print(\"Texts:\", split_texts)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e7486-4bab-4c07-a9de-5faef58c70dc",
   "metadata": {},
   "source": [
    "## Printing table with topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad8a5b0-4c7d-4a89-81ce-3511cc883f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\bertopic\\_bertopic.py:3507\u001b[0m, in \u001b[0;36mBERTopic._cluster_embeddings\u001b[1;34m(self, umap_embeddings, documents, partial_fit, y)\u001b[0m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3507\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhdbscan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mumap_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3508\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:1205\u001b[0m, in \u001b[0;36mHDBSCAN.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric_kwargs)\n\u001b[0;32m   1198\u001b[0m (\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_,\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobabilities_,\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_persistence_,\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condensed_tree,\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_linkage_tree,\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_spanning_tree,\n\u001b[1;32m-> 1205\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mhdbscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_finite:\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;66;03m# remap indices to align with original data in the case of non-finite entries.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:884\u001b[0m, in \u001b[0;36mhdbscan\u001b[1;34m(X, min_cluster_size, min_samples, alpha, cluster_selection_epsilon, max_cluster_size, metric, p, leaf_size, algorithm, memory, approx_min_span_tree, gen_min_span_tree, core_dist_n_jobs, cluster_selection_method, allow_single_cluster, match_reference_implementation, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m             (single_linkage_tree, result_min_span_tree) \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39mcache(\n\u001b[0;32m    869\u001b[0m                 _hdbscan_boruvka_balltree\n\u001b[0;32m    870\u001b[0m             )(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    880\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    881\u001b[0m             )\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 884\u001b[0m     \u001b[43m_tree_to_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_linkage_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_single_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatch_reference_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;241m+\u001b[39m (result_min_span_tree,)\n\u001b[0;32m    895\u001b[0m )\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:80\u001b[0m, in \u001b[0;36m_tree_to_labels\u001b[1;34m(X, single_linkage_tree, min_cluster_size, cluster_selection_method, allow_single_cluster, match_reference_implementation, cluster_selection_epsilon, max_cluster_size)\u001b[0m\n\u001b[0;32m     79\u001b[0m stability_dict \u001b[38;5;241m=\u001b[39m compute_stability(condensed_tree)\n\u001b[1;32m---> 80\u001b[0m labels, probabilities, stabilities \u001b[38;5;241m=\u001b[39m \u001b[43mget_clusters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondensed_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstability_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_single_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch_reference_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (labels, probabilities, stabilities, condensed_tree, single_linkage_tree)\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:659\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.get_clusters\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:733\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.get_clusters\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     topics, probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during model fitting: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\bertopic\\_bertopic.py:411\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[1;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[0;32m    408\u001b[0m umap_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce_dimensionality(embeddings, y)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Cluster reduced embeddings\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m documents, probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cluster_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mumap_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;66;03m# Sort and Map Topic IDs by their frequency\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_topics:\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\bertopic\\_bertopic.py:3509\u001b[0m, in \u001b[0;36mBERTopic._cluster_embeddings\u001b[1;34m(self, umap_embeddings, documents, partial_fit, y)\u001b[0m\n\u001b[0;32m   3507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhdbscan_model\u001b[38;5;241m.\u001b[39mfit(umap_embeddings, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m   3508\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m-> 3509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhdbscan_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mumap_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3511\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3512\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhdbscan_model\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:1205\u001b[0m, in \u001b[0;36mHDBSCAN.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1195\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1196\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric_kwargs)\n\u001b[0;32m   1198\u001b[0m (\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_,\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobabilities_,\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_persistence_,\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condensed_tree,\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_linkage_tree,\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_spanning_tree,\n\u001b[1;32m-> 1205\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mhdbscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_finite:\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;66;03m# remap indices to align with original data in the case of non-finite entries.\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condensed_tree \u001b[38;5;241m=\u001b[39m remap_condensed_tree(\n\u001b[0;32m   1210\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condensed_tree, internal_to_raw, outliers\n\u001b[0;32m   1211\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:884\u001b[0m, in \u001b[0;36mhdbscan\u001b[1;34m(X, min_cluster_size, min_samples, alpha, cluster_selection_epsilon, max_cluster_size, metric, p, leaf_size, algorithm, memory, approx_min_span_tree, gen_min_span_tree, core_dist_n_jobs, cluster_selection_method, allow_single_cluster, match_reference_implementation, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    868\u001b[0m             (single_linkage_tree, result_min_span_tree) \u001b[38;5;241m=\u001b[39m memory\u001b[38;5;241m.\u001b[39mcache(\n\u001b[0;32m    869\u001b[0m                 _hdbscan_boruvka_balltree\n\u001b[0;32m    870\u001b[0m             )(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    880\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    881\u001b[0m             )\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 884\u001b[0m     \u001b[43m_tree_to_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_linkage_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_single_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatch_reference_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;241m+\u001b[39m (result_min_span_tree,)\n\u001b[0;32m    895\u001b[0m )\n",
      "File \u001b[1;32m~\\Documents\\ibl_pan\\Lib\\site-packages\\hdbscan\\hdbscan_.py:80\u001b[0m, in \u001b[0;36m_tree_to_labels\u001b[1;34m(X, single_linkage_tree, min_cluster_size, cluster_selection_method, allow_single_cluster, match_reference_implementation, cluster_selection_epsilon, max_cluster_size)\u001b[0m\n\u001b[0;32m     78\u001b[0m condensed_tree \u001b[38;5;241m=\u001b[39m condense_tree(single_linkage_tree, min_cluster_size)\n\u001b[0;32m     79\u001b[0m stability_dict \u001b[38;5;241m=\u001b[39m compute_stability(condensed_tree)\n\u001b[1;32m---> 80\u001b[0m labels, probabilities, stabilities \u001b[38;5;241m=\u001b[39m \u001b[43mget_clusters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondensed_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstability_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_selection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_single_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch_reference_implementation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_cluster_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (labels, probabilities, stabilities, condensed_tree, single_linkage_tree)\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:659\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.get_clusters\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhdbscan\\\\_hdbscan_tree.pyx:733\u001b[0m, in \u001b[0;36mhdbscan._hdbscan_tree.get_clusters\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "print(topic_model.get_topic_info())\n",
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info.to_excel('jojs_topics_info.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ed207-814d-4c45-9082-197a0057702c",
   "metadata": {},
   "source": [
    "## Visualisation of topics via 2D representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6aec1-6370-438b-baa6-e9a7404cb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06f5ecf-4cfd-4cf6-a112-1452fcdc9b41",
   "metadata": {},
   "source": [
    "## Visualisation of topic hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611fabc1-4c8b-49bb-90ba-b3fc5095dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8b05b1-ea55-4f27-a2b5-e31652d38f21",
   "metadata": {},
   "source": [
    "## Visualisation of topic word scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4a504-026c-489b-9066-444409989a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0cdeaa-88c5-4fec-a4f7-3b5212b6fcb6",
   "metadata": {},
   "source": [
    "## Visualisation of topic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf6726-0330-4174-90da-024691a6c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
